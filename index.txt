1:"$Sreact.fragment"
2:I[3719,["17","static/chunks/17-9c04c9413a9f9f1f.js","874","static/chunks/874-6cc630662f3664af.js","862","static/chunks/862-15038af301665bb3.js","177","static/chunks/app/layout-d8117333dde1c2ea.js"],"ThemeProvider"]
3:I[768,["17","static/chunks/17-9c04c9413a9f9f1f.js","874","static/chunks/874-6cc630662f3664af.js","862","static/chunks/862-15038af301665bb3.js","177","static/chunks/app/layout-d8117333dde1c2ea.js"],"default"]
4:I[7555,[],""]
5:I[1295,[],""]
6:I[2548,["17","static/chunks/17-9c04c9413a9f9f1f.js","874","static/chunks/874-6cc630662f3664af.js","862","static/chunks/862-15038af301665bb3.js","177","static/chunks/app/layout-d8117333dde1c2ea.js"],"default"]
7:I[7437,["17","static/chunks/17-9c04c9413a9f9f1f.js","178","static/chunks/178-595a94b9af1e67b5.js","874","static/chunks/874-6cc630662f3664af.js","748","static/chunks/748-1f3129a1e6365cf9.js","974","static/chunks/app/page-085685ca794642ba.js"],"default"]
8:I[9507,["17","static/chunks/17-9c04c9413a9f9f1f.js","178","static/chunks/178-595a94b9af1e67b5.js","874","static/chunks/874-6cc630662f3664af.js","748","static/chunks/748-1f3129a1e6365cf9.js","974","static/chunks/app/page-085685ca794642ba.js"],"default"]
9:I[5218,["17","static/chunks/17-9c04c9413a9f9f1f.js","178","static/chunks/178-595a94b9af1e67b5.js","874","static/chunks/874-6cc630662f3664af.js","748","static/chunks/748-1f3129a1e6365cf9.js","974","static/chunks/app/page-085685ca794642ba.js"],"default"]
a:I[3684,["17","static/chunks/17-9c04c9413a9f9f1f.js","178","static/chunks/178-595a94b9af1e67b5.js","874","static/chunks/874-6cc630662f3664af.js","748","static/chunks/748-1f3129a1e6365cf9.js","974","static/chunks/app/page-085685ca794642ba.js"],"default"]
b:I[9665,[],"MetadataBoundary"]
d:I[9665,[],"OutletBoundary"]
10:I[4911,[],"AsyncMetadataOutlet"]
12:I[9665,[],"ViewportBoundary"]
14:I[6614,[],""]
:HL["/_next/static/css/9904c70f5604abd5.css","style"]
0:{"P":null,"b":"BJrlTfpG_MWzYJKh4m2L0","p":"","c":["",""],"i":false,"f":[[["",{"children":["__PAGE__",{}]},"$undefined","$undefined",true],["",["$","$1","c",{"children":[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/9904c70f5604abd5.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","html",null,{"lang":"en","className":"scroll-smooth","suppressHydrationWarning":true,"children":[["$","head",null,{"children":[["$","link",null,{"rel":"icon","href":"/favicon.svg","type":"image/svg+xml"}],["$","link",null,{"rel":"dns-prefetch","href":"https://google-fonts.jialeliu.com"}],["$","link",null,{"rel":"preconnect","href":"https://google-fonts.jialeliu.com","crossOrigin":""}],["$","link",null,{"rel":"preload","as":"style","href":"https://google-fonts.jialeliu.com/css2?family=Inter:wght@300;400;500;600;700&family=Crimson+Text:ital,wght@0,400;0,600;1,400&display=swap"}],["$","link",null,{"rel":"stylesheet","id":"gfonts-css","href":"https://google-fonts.jialeliu.com/css2?family=Inter:wght@300;400;500;600;700&family=Crimson+Text:ital,wght@0,400;0,600;1,400&display=swap","media":"print"}],["$","script",null,{"dangerouslySetInnerHTML":{"__html":"\n              (function(){\n                var l = document.getElementById('gfonts-css');\n                if (!l) return;\n                if (l.media !== 'all') {\n                  l.addEventListener('load', function(){ try { l.media = 'all'; } catch(e){} });\n                }\n              })();\n            "}}],["$","noscript",null,{"children":["$","link",null,{"rel":"stylesheet","href":"https://google-fonts.jialeliu.com/css2?family=Inter:wght@300;400;500;600;700&family=Crimson+Text:ital,wght@0,400;0,600;1,400&display=swap"}]}],["$","script",null,{"dangerouslySetInnerHTML":{"__html":"\n              try {\n                const theme = localStorage.getItem('theme-storage');\n                const parsed = theme ? JSON.parse(theme) : null;\n                const setting = parsed?.state?.theme || 'system';\n                const prefersDark = typeof window !== 'undefined' && window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches;\n                const effective = setting === 'dark' ? 'dark' : (setting === 'light' ? 'light' : (prefersDark ? 'dark' : 'light'));\n                var root = document.documentElement;\n                root.classList.add(effective);\n                root.setAttribute('data-theme', effective);\n              } catch (e) {\n                var root = document.documentElement;\n                root.classList.add('light');\n                root.setAttribute('data-theme', 'light');\n              }\n            "}}]]}],["$","body",null,{"className":"font-sans antialiased","children":["$","$L2",null,{"children":[["$","$L3",null,{"items":[{"title":"About","type":"page","target":"about","href":"/"},{"title":"Publications","type":"page","target":"publications","href":"/publications"},{"title":"Teaching","type":"page","target":"teaching","href":"/teaching"},{"title":"Awards","type":"page","target":"awards","href":"/awards"},{"title":"CV","type":"page","target":"cv","href":"/cv"}],"siteTitle":"Penghui Ruan","enableOnePageMode":false}],["$","main",null,{"className":"min-h-screen pt-16 lg:pt-20","children":["$","$L4",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":404}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]],[]],"forbidden":"$undefined","unauthorized":"$undefined"}]}],["$","$L6",null,{"lastUpdated":"December 2, 2025"}]]}]}]]}]]}],{"children":["__PAGE__",["$","$1","c",{"children":[["$","div",null,{"className":"max-w-6xl mx-auto px-4 sm:px-6 lg:px-8 py-8 bg-background min-h-screen","children":["$","div",null,{"className":"grid grid-cols-1 lg:grid-cols-3 gap-12","children":[["$","div",null,{"className":"lg:col-span-1","children":["$","$L7",null,{"author":{"name":"Penghui Ruan","title":"PhD Candidate","institution":"The Hong Kong Polytechnic University","avatar":"/bio.jpg"},"social":{"email":"penghui.ruan@connect.polyu.hk","location":"Hong Kong, China","location_url":"https://maps.google.com/?q=Hong+Kong+Polytechnic+University","location_details":["The Hong Kong Polytechnic University,","Hung Hom, Kowloon, Hong Kong"],"google_scholar":"https://scholar.google.com/citations?user=tTUajvgAAAAJ&hl=en&oi=ao","orcid":"https://orcid.org/0000-0003-0238-299X","github":"https://github.com/PR-Ryan/","linkedin":"https://www.linkedin.com/in/penghui-ruan-221469231/"},"features":{"enable_likes":true,"enable_one_page_mode":false},"researchInterests":["Video Generation","Video Editing","World Model","3D Vision"]}]}],["$","div",null,{"className":"lg:col-span-2 space-y-8","children":[["$","section","about",{"id":"about","className":"scroll-mt-24 space-y-8","children":[[["$","$L8","about",{"content":"I am a fourth-year Ph.D. candidate at The Hong Kong Polytechnic University (PolyU), supervised by [Prof. Jiannong Cao](https://www4.comp.polyu.edu.hk/~csjcao/) and [Prof. Yuhui Shi](https://www.sustech.edu.cn/en/faculties/shiyuhui.html) at Southern University of Science and Technology (SUSTech). During my Ph.D. studies, I have closely collaborated with [Dr. Pichao Wang](https://wangpichao.github.io/) from NVIDIA.\n\nI received my B.E. in Computer Science and Technology from SUSTech in 2021, where I graduated in the top 10% of my class. I was also an exchange student at the University of Wisconsin-Madison (2020).\n\nMy current research focuses on **Video Generation**, **Video Editing**, **World Model** and **3D Vision**, with a particular emphasis on diffusion models and their applications in visual content generation and manipulation.\n\n[I am currently actively seeking internship and full-time positions starting in 2026.]()\n","title":"About"}],["$","$L9","featured_publications",{"publications":[{"id":"huang2025refaccadeeditingobjectgiven","title":"Refacade: Editing Object with Given Reference Texture","authors":[{"name":"Youze Huang","isHighlighted":false,"isCorresponding":true,"isCoAuthor":false},{"name":"Penghui Ruan","isHighlighted":false,"isCorresponding":true,"isCoAuthor":false},{"name":"Bojia Zi","isHighlighted":false,"isCorresponding":true,"isCoAuthor":false},{"name":"Xianbiao Qi","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Jianan Wang","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Rong Xiao","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false}],"year":2025,"type":"preprint","status":"published","tags":[],"keywords":"$0:f:0:1:2:children:1:props:children:0:props:children:props:children:1:props:children:0:props:children:0:1:props:publications:0:tags","researchArea":"machine-learning","journal":"","conference":"","abstract":"","description":"Under Review, Equal contribution","selected":true,"bibtex":"@misc{huang2025refaccadeeditingobjectgiven,\n  title = {Refacade: Editing Object with Given Reference Texture},\n  author = {Youze Huang and Penghui Ruan and Bojia Zi and Xianbiao Qi and Jianan Wang and Rong Xiao},\n  year = {2025},\n  note = {Under Review, Equal contribution}\n}"},{"id":"ruanctrl","title":"Ctrl&Shift: High-Quality Geometry-Aware Object Manipulation in Visual Generation","authors":[{"name":"Penghui Ruan","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Bojia Zi","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Youze Huang","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Pichao Wang","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Xianbiao Qi","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Rong Xiao","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Jiannong Cao","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Yuhui Shi.","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false}],"year":2025,"type":"preprint","status":"published","tags":[],"keywords":"$0:f:0:1:2:children:1:props:children:0:props:children:props:children:1:props:children:0:props:children:0:1:props:publications:1:tags","researchArea":"machine-learning","journal":"","conference":"","abstract":"","description":"Under Review","selected":true,"bibtex":"@misc{ruanctrl,\n  title = {Ctrl&Shift: High-Quality Geometry-Aware Object Manipulation in Visual Generation},\n  author = {Penghui Ruan and Bojia Zi and Youze Huang and Pichao Wang and Xianbiao Qi and Rong Xiao and Jiannong Cao and Yuhui Shi.},\n  year = {2025},\n  note = {Under Review}\n}"},{"id":"ruanjdm","title":"JDM: Joint Distribution Modeling for Fine-Grained Text-to-Video Generation","authors":[{"name":"Penghui Ruan","isHighlighted":false,"isCorresponding":true,"isCoAuthor":false},{"name":"Bojia Zi","isHighlighted":false,"isCorresponding":true,"isCoAuthor":false},{"name":"Youze Huang","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Pichao Wang","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Xianbiao Qi","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Rong Xiao","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Jiannong Cao","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Yuhui Shi.","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false}],"year":2025,"type":"preprint","status":"published","tags":[],"keywords":"$0:f:0:1:2:children:1:props:children:0:props:children:props:children:1:props:children:0:props:children:0:1:props:publications:2:tags","researchArea":"machine-learning","journal":"","conference":"","abstract":"","description":"Under Review, Equal contribution","selected":true,"bibtex":"@misc{ruanjdm,\n  title = {JDM: Joint Distribution Modeling for Fine-Grained Text-to-Video Generation},\n  author = {Penghui Ruan and Bojia Zi and Youze Huang and Pichao Wang and Xianbiao Qi and Rong Xiao and Jiannong Cao and Yuhui Shi.},\n  year = {2025},\n  note = {Under Review, Equal contribution}\n}"},{"id":"zi2025senorita","title":"Señorita-2M: A High-Quality Instruction-Based Dataset for General Video Editing by Video Specialists","authors":[{"name":"Bojia Zi","isHighlighted":false,"isCorresponding":true,"isCoAuthor":false},{"name":"Penghui Ruan","isHighlighted":false,"isCorresponding":true,"isCoAuthor":false},{"name":"Xianbiao Qi","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Shaozhe Hao","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Shihao Zhao","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Youze Huang","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Bin Liang","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Rong Xiao","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Kam-Fai Wong","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false}],"year":2025,"type":"conference","status":"published","tags":[],"keywords":"$0:f:0:1:2:children:1:props:children:0:props:children:props:children:1:props:children:0:props:children:0:1:props:publications:3:tags","researchArea":"machine-learning","journal":"","conference":"Advances in Neural Information Processing Systems (NeurIPS) 2025","abstract":"","description":"Accepted, Equal contribution","selected":true,"bibtex":"@inproceedings{zi2025senorita,\n  title = {Señorita-2M: A High-Quality Instruction-Based Dataset for General Video Editing by Video Specialists},\n  author = {Zi, Bojia and Ruan, Penghui and Qi, Xianbiao and Hao, Shaozhe and Zhao, Shihao and Huang, Youze and Liang, Bin and Xiao, Rong and Wong, Kam-Fai},\n  booktitle = {Advances in Neural Information Processing Systems (NeurIPS) 2025},\n  year = {2025},\n  note = {Accepted, Equal contribution}\n}"},{"id":"ruan2024enhancing","title":"Enhancing Motion in Text-to-Video Generation with Decomposed Encoding and Conditioning","authors":[{"name":"Penghui Ruan","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Pichao Wang","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Divya Saxena","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Jiannong Cao","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Yuhui Shi","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false}],"year":2024,"type":"conference","status":"published","tags":[],"keywords":"$0:f:0:1:2:children:1:props:children:0:props:children:props:children:1:props:children:0:props:children:0:1:props:publications:4:tags","researchArea":"machine-learning","journal":"","conference":"Advances in Neural Information Processing Systems (NeurIPS) 2024","abstract":"","description":"Accepted","selected":true,"bibtex":"@inproceedings{ruan2024enhancing,\n  title = {Enhancing Motion in Text-to-Video Generation with Decomposed Encoding and Conditioning},\n  author = {Ruan, Penghui and Wang, Pichao and Saxena, Divya and Cao, Jiannong and Shi, Yuhui},\n  booktitle = {Advances in Neural Information Processing Systems (NeurIPS) 2024},\n  year = {2024},\n  note = {Accepted}\n}"}],"title":"Selected Publications","enableOnePageMode":true}],["$","$La","internship",{"config":{"type":"card","title":"Professional Experience","items":[{"title":"Applied Scientist Intern","subtitle":"Amazon","date":"Oct 2025 - Present","content":"Researching and developing foundational models for high-quality movie dubbing with precise lip synchronization and video preservation.","tags":["Amazon","Seattle","Research"]},{"title":"AIGC Research Intern","subtitle":"IntelliFusion Inc.","date":"Dec 2024 - Oct 2025","content":"Built and trained large-scale T2V/video-editing models with fine-grained control over content via textual conditioning and explicit 3D camera control. Spearheading the creation of a large-scale, multi-task instructional video editing dataset.","tags":["IntelliFusion","Shenzhen","AI"]},{"title":"Software Engineer Intern","subtitle":"Tencent","date":"Apr 2021 - Jun 2021","content":"Migrated sensitive word filtering service from HTTPS to TRPC, optimizing efficiency and enhancing security. Contributed to the Routing Service for video search.","tags":["Tencent","Shenzhen","Engineering"]}]},"embedded":true}],["$","$La","education",{"config":{"type":"card","title":"Education","items":[{"title":"Ph.D. in Computer Science","subtitle":"The Hong Kong Polytechnic University","date":"Sep 2022 - Aug 2026 (Expected)","content":"Specializing in Text-to-Video Generation, Video Editing, and 3D Vision. Advisors: Prof. Jiannong Cao and Prof. Yuhui Shi.","tags":["PhD","Computer Science","Hong Kong"]},{"title":"B.E. in Computer Science and Technology","subtitle":"Southern University of Science and Technology","date":"Sep 2017 - Jun 2021","content":"GPA: 3.74/4.00 (Top 10%)","tags":["Bachelor","Computer Science","China"]},{"title":"Exchange Student","subtitle":"University of Wisconsin-Madison","date":"Jan 2020 - Sep 2020","content":"GPA: 3.83/4.0 (Top 5%)","tags":["Exchange Student","Computer Science","USA"]}]},"embedded":true}]],false,false,false]}]]}]]}]}],["$","$Lb",null,{"children":"$Lc"}],null,["$","$Ld",null,{"children":["$Le","$Lf",["$","$L10",null,{"promise":"$@11"}]]}]]}],{},null,false]},null,false],["$","$1","h",{"children":[null,["$","$1","xmdCBiy8v3Px1amh3XN6r",{"children":[["$","$L12",null,{"children":"$L13"}],null]}],null]}],false]],"m":"$undefined","G":["$14","$undefined"],"s":false,"S":true}
15:"$Sreact.suspense"
16:I[4911,[],"AsyncMetadata"]
c:["$","$15",null,{"fallback":null,"children":["$","$L16",null,{"promise":"$@17"}]}]
f:null
13:[["$","meta","0",{"charSet":"utf-8"}],["$","meta","1",{"name":"viewport","content":"width=device-width, initial-scale=1"}]]
e:null
17:{"metadata":[["$","title","0",{"children":"Penghui Ruan"}],["$","meta","1",{"name":"description","content":"PhD Candidate at The Hong Kong Polytechnic University, specializing in Text-to-Video Generation, Video Editing, and 3D Vision."}],["$","meta","2",{"name":"author","content":"Penghui Ruan"}],["$","meta","3",{"name":"keywords","content":"Penghui Ruan,PhD,Research,The Hong Kong Polytechnic University"}],["$","meta","4",{"name":"creator","content":"Penghui Ruan"}],["$","meta","5",{"name":"publisher","content":"Penghui Ruan"}],["$","meta","6",{"property":"og:title","content":"Penghui Ruan"}],["$","meta","7",{"property":"og:description","content":"PhD Candidate at The Hong Kong Polytechnic University, specializing in Text-to-Video Generation, Video Editing, and 3D Vision."}],["$","meta","8",{"property":"og:site_name","content":"Penghui Ruan's Academic Website"}],["$","meta","9",{"property":"og:locale","content":"en_US"}],["$","meta","10",{"property":"og:type","content":"website"}],["$","meta","11",{"name":"twitter:card","content":"summary"}],["$","meta","12",{"name":"twitter:title","content":"Penghui Ruan"}],["$","meta","13",{"name":"twitter:description","content":"PhD Candidate at The Hong Kong Polytechnic University, specializing in Text-to-Video Generation, Video Editing, and 3D Vision."}],["$","link","14",{"rel":"icon","href":"/favicon.svg"}]],"error":null,"digest":"$undefined"}
11:{"metadata":"$17:metadata","error":null,"digest":"$undefined"}
